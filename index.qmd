---
title: "Detecting Anomalous Cybersecurity Events Using LSTM Networks"
subtitle: "A Case Study on the BETH Dataset"
author: "Lionel & Killian (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: inline
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)


## Introduction

With ever-growing complexity and interconnectedness in modern digital infrastructures, the attack surface has expanded appreciably, posing serious threats for organizations and individuals. Cybersecurity breaches, specifically advanced process-level intrusions aimed at crucial systems, have increased in quantity and complexity. Traditional rule-based detection tools and static feature engineering solutions are often ineffective for finding new threats exploiting temporal patterns or masquerading as benign activity. To meet this state, there is a need for the construction of resilient, dynamic, and data-driven models able to learn system activity in the real world to effectively identify anomalies.
In sequence modeling machine learning techniques, the Long Short-Term Memory (LSTM) networks have been important for the learning of long-range temporal relationships in sequential data such as speech (Graves et al., 2013), language (Sundermeyer et al., 2012), and biomedical signals (Lipton et al., 2016). Initially introduced by Hochreiter and Schmidhuber (1997), the LSTM networks enhance the traditional recurrent neural network (RNN) architecture through the addition of memory cells and gate mechanisms for the storage and selective forgetfulness of long-range time-series relationships. For these reasons, the use of LSTM is a natural choice in the representation of the behavior of the host in cybersecurity systems where the order of the execution of processes, the timing, and the context in which they are executed are of crucial semantic information.
Despite the promise of deep learning for the application of anomaly detection, most of the cybersecurity work relies on outdated or synthetic datasets such as the KDD Cup 1999 (Hettich & Bay, 1999), NSL-KDD (Tavallaee et al., 2009), and the ISCX IDS 2012 (Shiravi et al., 2012). Such datasets are lacking in the sort of diversity, realism, and granularity required to validate models within modern operating conditions. For instance, the BPF-extended tracking honeypot (BETH) dataset (Highnam et al., 2021) is a quantum leap in the field. It consists of well over eight million process-level events, meticulously labelled and gathered through extended Berkeley Packet Filter (eBPF) instrumentation on live cloud-hosted honeypots. It is important to note that the dataset consists of benign and adversarial host activity in natural operating conditions along with comprehensive temporal details and proper labels.
In our paper, we discuss the use of LSTM networks to characterize benign system activity and discern process-level anomalies through the usage of the BETH dataset. Unlike the common supervised learning scenario in which there are annotated examples of all attack modes, we embrace the semi-supervised method to detecting anomalies: the LSTM model is trained only on benign activity in order to reveal the hidden structure and temporal dynamics of typical host behavior. Under test, deviations of the acquired pattern are signaled as potential anomalies. Our contributions are the following:
We propose a sequence-based LSTM model trained on real-world benign process logs for anomaly detection. We benchmark the model on a modern, cloud-native dataset (BETH) containing labeled attack sequences. We evaluate the model using both classification metrics (e.g., precision, recall) and temporal anomaly scoring, comparing its performance to traditional baselines. This study contributes to the growing body of literature on robust machine learning for cybersecurity and demonstrates the applicability of temporal deep learning models in detecting nuanced and context-dependent threats in dynamic environments.


## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*


*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
